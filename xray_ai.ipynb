{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xray_ai.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devpranoy/chest_xray_ai/blob/master/xray_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "gknelDECVGgD",
        "colab_type": "code",
        "outputId": "f4c4cb9f-3396-4d3c-84b9-f205e07464e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Importing DRIVE\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XWNkTu1chH_8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "\n",
        "## Specify appropriate transforms, and batch_sizes\n",
        "\n",
        "batch_size = 4\n",
        "num_workers = 0\n",
        "\n",
        "data_dir = '/content/drive/My Drive/Complete Xray data set filtered'\n",
        "train_dir = os.path.join(data_dir, 'train/')\n",
        "valid_dir = os.path.join(data_dir, 'valid/')\n",
        "test_dir = os.path.join(data_dir, 'test/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yw5y8W7rhyAG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "standard_normalization = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                              std=[0.229, 0.224, 0.225])\n",
        "data_transforms = {'train': transforms.Compose([transforms.RandomResizedCrop(224),\n",
        "    \n",
        "                                     transforms.Grayscale(num_output_channels=3),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     standard_normalization]),\n",
        "                   'val': transforms.Compose([transforms.Resize(256),\n",
        "                                     transforms.CenterCrop(224),\n",
        "                                     transforms.Grayscale(num_output_channels=3),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     standard_normalization]),\n",
        "                   'test': transforms.Compose([transforms.Resize(size=(224,224)),\n",
        "                                     transforms.Grayscale(num_output_channels=3),\n",
        "                                     transforms.ToTensor(), \n",
        "                                     standard_normalization])\n",
        "                  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NV4WD3RHiA9c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
        "valid_data = datasets.ImageFolder(valid_dir, transform=data_transforms['val'])\n",
        "test_data = datasets.ImageFolder(test_dir, transform=data_transforms['test'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5mf_-YsXiEqX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                           batch_size=batch_size, \n",
        "                                           num_workers=num_workers,\n",
        "                                           shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data,\n",
        "                                           batch_size=batch_size, \n",
        "                                           num_workers=num_workers,\n",
        "                                           shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_data,\n",
        "                                           batch_size=batch_size, \n",
        "                                           num_workers=num_workers,\n",
        "                                           shuffle=False)\n",
        "loaders_transfer = {\n",
        "    'train': train_loader,\n",
        "    'valid': valid_loader,\n",
        "    'test': test_loader\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oSH6MpeJkG8p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# check if CUDA is available\n",
        "use_cuda = torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ATEiynj7kLYB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "num_classes = 14 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nPXy2RlOkRJv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "23349cdc-8743-4026-c5ff-528363849882"
      },
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "#Specify model architecture \n",
        "model_transfer = models.resnet50(pretrained=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.torch/models/resnet50-19c8e357.pth\n",
            "102502400it [00:03, 32797132.27it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "AfeFdRSQm_fe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for param in model_transfer.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dkM2OJZhnEHg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model_transfer.fc = nn.Linear(2048, 14, bias=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JzHqt3FenH8Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fc_parameters = model_transfer.fc.parameters()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AK64v6AhnKDv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "for param in fc_parameters:\n",
        "    param.requires_grad = True\n",
        "\n",
        "if use_cuda:\n",
        "    model_transfer = model_transfer.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z36S3j11nNZZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion_transfer = nn.CrossEntropyLoss()\n",
        "optimizer_transfer = optim.SGD(model_transfer.fc.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4fk_rTqtnPqF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
        "    \"\"\"returns trained model\"\"\"\n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf\n",
        "    \n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        # initialize variables to monitor training and validation loss\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        \n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "\n",
        "            # initialize weights to zero\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            output = model(data)\n",
        "            \n",
        "            # calculate loss\n",
        "            loss = criterion(output, target)\n",
        "            \n",
        "            # back prop\n",
        "            loss.backward()\n",
        "            \n",
        "            # grad\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "            \n",
        "            if batch_idx % 100 == 0:\n",
        "                print('Epoch %d, Batch %d loss: %.6f' %\n",
        "                  (epoch, batch_idx + 1, train_loss))\n",
        "        \n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "        model.eval()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            ## update the average validation loss\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
        "\n",
        "            \n",
        "        # print training/validation statistics \n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "            epoch, \n",
        "            train_loss,\n",
        "            valid_loss\n",
        "            ))\n",
        "        \n",
        "        ## TODO: save the model if validation loss has decreased\n",
        "        if valid_loss < valid_loss_min:\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "            valid_loss_min,\n",
        "            valid_loss))\n",
        "            valid_loss_min = valid_loss\n",
        "            \n",
        "    # return trained model\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qhMu-gLRnTT6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "fc94cfb9-b9c1-4280-d577-5d579391cf82"
      },
      "cell_type": "code",
      "source": [
        "train(10, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_transfer.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Batch 1 loss: 1.876416\n",
            "Epoch 1, Batch 101 loss: 1.310689\n",
            "Epoch 1, Batch 201 loss: 1.367774\n",
            "Epoch 1, Batch 301 loss: 1.393406\n",
            "Epoch 1, Batch 401 loss: 1.419597\n",
            "Epoch 1, Batch 501 loss: 1.432603\n",
            "Epoch 1, Batch 601 loss: 1.430640\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U219qlannYm7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_transfer.load_state_dict(torch.load('model_transfer.pt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NVqXgDQinc8C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test(loaders, model, criterion, use_cuda):\n",
        "\n",
        "    # monitor test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
        "        # move to GPU\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average test loss \n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        # convert output probabilities to predicted class\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        # compare predictions to true label\n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "            \n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
        "        100. * correct / total, correct, total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_bJFDq-joCIY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test(loaders_transfer, model_transfer, criterion_transfer, use_cuda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YT6VNK7foFMj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class_names = [item[4:].replace(\"_\", \" \") for item in loaders_transfer['train'].dataset.classes]\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "def load_input_image(img_path):    \n",
        "    image = Image.open(img_path).convert('RGB')\n",
        "    prediction_transform = transforms.Compose([transforms.Resize(size=(224, 224)),\n",
        "                                     transforms.Grayscale(num_output_channels=3),\n",
        "                                     transforms.ToTensor(), \n",
        "                                     standard_normalization])\n",
        "\n",
        "    # discard the transparent, alpha channel (that's the :3) and add the batch dimension\n",
        "    image = prediction_transform(image)[:3,:,:].unsqueeze(0)\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qhlObwlkoQgF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict_teeth_transfer(model, class_names, img_path):\n",
        "    # load the image and return the predicted teeth \n",
        "    img = load_input_image(img_path)\n",
        "    model = model.cpu()\n",
        "    model.eval()\n",
        "    idx = torch.argmax(model(img))\n",
        "    return class_names[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8jRAEia0oYLr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Prediction Testing"
      ]
    },
    {
      "metadata": {
        "id": "XDUgQV9FoTA8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "for img_file in os.listdir('/content/drive/My Drive/Complete Xray data set filtered/test/002.Cardiomegaly'):\n",
        "    img_path = os.path.join('/content/drive/My Drive/Complete Xray data set filtered/test/002.Cardiomegaly', img_file)\n",
        "    predition = predict_teeth_transfer(model_transfer, class_names, img_path)\n",
        "    print(\"image_file_name: {0}, \\t Disease Prediction: {1}\".format(img_path, predition))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}